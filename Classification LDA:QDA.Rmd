---
title: "Classification 2"
author: "Raghav Arora"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(kknn)
library(glmnet)
library(discrim)
```

# LDA

```{r, message = FALSE}
ins <- read_csv("https://www.dropbox.com/s/bocjjyo1ehr5auz/insurance.csv?dl=1")

ins <- ins %>%
  mutate(
    smoker = factor(smoker)
  ) %>%
  drop_na()
```

```{r set_mod}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")
```

```{r}
lda_fit_1 <- lda_mod %>%
  fit(smoker ~ charges, data = ins)

lda_fit_1$fit %>% summary()
```

```{r}
lda_fit_1 
```

```{r}
preds <- lda_fit_1 %>% predict(ins)

ins <- ins %>%
  mutate(
    pred_smoker = preds$.pred_class
  )

ins %>%
  accuracy(truth = smoker,
           estimate = pred_smoker)
```

```{r}
lda_fit_2 <- lda_mod %>%
  fit(smoker ~ charges + age, data = ins)

lda_fit_2
```

```{r}
lda_fit_2$fit$scaling
```

```{r, echo = FALSE}
ins %>%
  ggplot(aes(x = charges, y = age, color = smoker)) +
  geom_point()
```

```{r}
lda_fit_2

my_slope = lda_fit_2$fit$scaling[1]/(-1*lda_fit_2$fit$scaling[2])
```

```{r, echo = FALSE}

ins %>%
  ggplot(aes(x = charges, y = age, color = smoker)) +
  geom_point() +
  geom_abline(aes(slope = my_slope, intercept = 0))
```

#### Your turn:

Find the best LDA model to predict smoker status.

```{r}
ins_cv = vfold_cv(ins, v = 10)

recipe1 <- recipe(smoker ~ charges + bmi, data = ins) %>% 
  step_normalize(all_numeric())

recipe2 <- recipe(smoker ~ charges + sex, data = ins) %>% 
  step_normalize(all_numeric())

recipe3 <- recipe(smoker ~ charges + age + bmi, data = ins) %>% 
  step_normalize(all_numeric())
```

```{r}

LDA_wflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(recipe1)

lda_fit_3 <- LDA_wflow %>% 
  fit_resamples(ins_cv)

lda_fit_3 %>% collect_metrics()
```

```{r}
LDA_wflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(recipe2)

lda_fit_4 <- LDA_wflow %>% 
  fit_resamples(ins_cv)

lda_fit_4 %>% collect_metrics()
```

```{r}
LDA_wflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(recipe3)

lda_fit_5 <- LDA_wflow %>% 
  fit_resamples(ins_cv)

lda_fit_5 %>% collect_metrics()
```

-   Recipe 3/lda_fit_5 has the highest accuracy and roc_auc

How does it compare to the Logistic Regression and KNN approaches?

# Logistic Regression 

```{r}
log <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

log_wflow <- workflow() %>% 
  add_model(log) %>% 
  add_recipe(recipe3)

log_wflow %>% 
  fit_resamples(ins_cv) %>% 
  collect_metrics()

```

# KNN

```{r}
knn <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

knn_wflow <- workflow() %>% 
  add_model(knn) %>% 
  add_recipe(recipe3)

k_grid <- grid_regular(neighbors(c(2, 50)), levels = 10)
set.seed(7)

knn_k <- knn_wflow %>% 
  tune_grid(resamples = ins_cv,
            grid = k_grid)

knn_k %>% show_best('roc_auc') 
```
The best roc_auc is at n=12

```{r}
knn1 <- nearest_neighbor(neighbors = 12) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")

knn_wflow <- workflow() %>% 
  add_model(knn1) %>% 
  add_recipe(recipe3)

knn_fit <- knn_wflow %>% 
  fit_resamples(ins_cv)

knn_fit %>% collect_metrics()
```

- The best model is between logistic and Knn followed by LDA.

# Quadratic Discriminant Analysis

#### Code from lecture:

```{r qda_mod}
qda_mod <- discrim_regularized(frac_common_cov = 0) %>% 
             set_engine('klaR') %>% 
             set_mode('classification')
```

```{r, echo = FALSE}
dat <- tibble(
  A = rnorm(100, 10, 5),
  B = rnorm(100, 15, 1)
) %>%
  pivot_longer(everything(),
               values_to = "val",
               names_to = "Class")

ggplot(dat, aes(x = val, fill = Class)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 11)
```

```{r, echo = FALSE}
dat <- tibble(
  V1 = c(rnorm(100, 10, 5), rnorm(100, 37, 18)),
  V2 = c(rnorm(100, 15, 1), rnorm(100, 30, 9)),
  Class = factor(c(rep("A", 100), rep("B", 100)))
) 

dat %>%
  ggplot(aes(x = V1, y = V2, col = Class)) +
  geom_point()
```

```{r, echo = FALSE}
qda_wflow <- workflow() %>%
  add_recipe(recipe(Class ~ V1 + V2, data = dat)) %>%
  add_model(qda_mod) %>%
  fit(dat)

```

#### Your turn:

Find the best QDA model to predict smoker status.

```{r}
qda_wflow <- workflow() %>%
  add_recipe(recipe1) %>%
  add_model(qda_mod) 

qda_wflow %>% 
  fit_resamples(ins_cv) %>% 
  collect_metrics()  
```

```{r}
qda_wflow <- workflow() %>%
  add_recipe(recipe2) %>%
  add_model(qda_mod) 

qda_wflow %>% 
  fit_resamples(ins_cv) %>% 
  collect_metrics()  
```

```{r}
qda_wflow <- workflow() %>%
  add_recipe(recipe3) %>%
  add_model(qda_mod) 

qda_wflow %>% 
  fit_resamples(ins_cv) %>% 
  collect_metrics()  
```
Recipe 3 has the best metrics for QDA as well.

How does it compare to the LDA, Logistic Regression, and KNN approaches?

With regards to recipe 3, QDA, KNN and Logistic Regression are pretty similar with LDA being the worst model. 

# Metrics

<https://yardstick.tidymodels.org/articles/metric-types.html>
